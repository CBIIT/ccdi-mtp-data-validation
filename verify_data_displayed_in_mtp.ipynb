{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation 3:  Verify that data appears as expected within the MTP UI\n",
    "2022-10-28 ZD  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "### \"Does the MTP UI match the MTP database?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "This validation will test “completeness and accuracy of data loaded into the platform” and follow MTP Data Validations 1&2. It will compare the data displayed within the platform GUI (after loading) to the expected values within the data (before loading). Automated scripts will pull test cases from the data that can be fed into platform testing automations to check displays for completeness and accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope\n",
    "DV3 will focus on displays within the platform that relate to new pediatric data, including those that happen to incorporate Open Targets (OT) data. New pediatric data includes the Food and Drug Administration’s Pediatric Molecular Target Lists (FDA PMTL); the much larger collection of evidence data provided by the Children’s Hospital of Philadelphia (CHoP); and derived summary tables, such as the Pediatric Cancer Data Navigation (PCDN) page. It will not validate or test displays that only include OT data without pediatric data.  \n",
    "\n",
    "The testing within DV3 will use sampling (spot-checking) methods, though scalability to meet automation capacity will be a design goal. Samples tested will include a set of defined high-profile genes and diseases that we expect will garner an abundance of user attention. We will also include a random sampling of genes and diseases (associated with CHoP data) to expand testing scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Overview\n",
    "\n",
    "Testable values for each test case will be contained in a tab within the output Excel\n",
    "\n",
    "1. Target Association\n",
    "    - Count of associated diseases\n",
    "    - PMTL annotation\n",
    "2. Target Profile Page\n",
    "    - Somatic Alterations widget\n",
    "        - Status\n",
    "        - Row count of each of 5 tabs\n",
    "    - Gene Expression widget\n",
    "        - Status\n",
    "3. Disease Association\n",
    "    - Count of associated targets\n",
    "4. Evidence Page\n",
    "    - Somatic Alterations widget\n",
    "        - Status\n",
    "        - Row count of each of 5 tabs\n",
    "    - Gene Expression widget\n",
    "        - Status   \n",
    "5. Pediatric Cancer Data Navigation (PCDN) Page\n",
    "    - Row count of resulting evidence pages when searching for target or disease\n",
    "6. Pediatric Molecular Targets List (PMTL) Page\n",
    "    - Row count of Relevant and Non-Relevant targets  \n",
    "\n",
    "---\n",
    "\n",
    "### Updates\n",
    "\n",
    "**2022-11-15**\n",
    "- Generate and export new PCDN instead of ingesting\n",
    "- Add random seed for reproducible random results\n",
    "- Change Excel export to function with dictionary input for more flexibility\n",
    "\n",
    "**2022-11-16**\n",
    "- Update PCDN export functions\n",
    "    - Export PCDN as partitioned JSONL files\n",
    "    - Compress files into one folder\n",
    "    - Create md5 checksum\n",
    "- Edit output data file structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and define relative paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import hashlib\n",
    "import shutil\n",
    "\n",
    "import ndjson\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORE VERSIONS\n",
    "OT_VERSION = '22.04'\n",
    "OPENPEDCAN_VERSION = 'v11.1'\n",
    "PMTL_VERSION = 'v3.0'\n",
    "RANDOM_SEED = 5555\n",
    "\n",
    "# --------\n",
    "\n",
    "# INPUTS\n",
    "\n",
    "# Data from Open Targets\n",
    "OT_PATH = 'data/external/opentargets/platform/' + OT_VERSION + '/output/etl/json/'\n",
    "\n",
    "OT_ASSC_OVERALLDIRECT_PATH = OT_PATH + 'associationByOverallDirect/'\n",
    "OT_ASSC_OVERALLINDIRECT_PATH = OT_PATH + 'associationByOverallIndirect/'\n",
    "OT_DISEASES_PATH = OT_PATH + 'diseases/'\n",
    "OT_TARGETS_PATH = OT_PATH + 'targets/'\n",
    "\n",
    "# Data from CHoP\n",
    "CHOP_PATH = 'data/raw/OpenPedCan_' + OPENPEDCAN_VERSION + '/'\n",
    "\n",
    "# CHoP: Somatic Alterations\n",
    "CNV_PATH = CHOP_PATH + 'gene-level-cnv-consensus-annotated-mut-freq.jsonl.gz'\n",
    "SNVGENE_PATH = CHOP_PATH + 'gene-level-snv-consensus-annotated-mut-freq.jsonl.gz'\n",
    "SNV_PATH = CHOP_PATH + 'variant-level-snv-consensus-annotated-mut-freq.jsonl.gz'\n",
    "FUSIONGENE_PATH = CHOP_PATH + 'putative-oncogene-fused-gene-freq.jsonl.gz'\n",
    "FUSION_PATH = CHOP_PATH + 'putative-oncogene-fusion-freq.jsonl.gz'\n",
    "\n",
    "# CHoP: Gene Expression\n",
    "TPMGENE_PATH = CHOP_PATH + 'long_n_tpm_mean_sd_quantile_gene_wise_zscore.jsonl.gz'\n",
    "TPMGROUP_PATH = CHOP_PATH + 'long_n_tpm_mean_sd_quantile_group_wise_zscore.jsonl.gz'\n",
    "\n",
    "# PMTL data\n",
    "PMTL_PATH = 'data/processed/pmtl_' + PMTL_VERSION + '.json'\n",
    "\n",
    "# Priority targets and diseases for test cases\n",
    "PRIORITY_PATH = 'data/processed/dv3_priority_tests/'\n",
    "PRIORITY_TARGETS_PATH = PRIORITY_PATH + 'targets.csv'\n",
    "PRIORITY_DISEASES_PATH = PRIORITY_PATH + 'diseases.csv'\n",
    "PRIORITY_EVIDENCES_PATH = PRIORITY_PATH + 'evidences.csv'\n",
    "\n",
    "# --------\n",
    "\n",
    "# OUTPUTS\n",
    "\n",
    "# Excel file for DV3 automation input\n",
    "XLSX_OUTPUT = 'dv3_test_cases/MTP_DV3_' + OT_VERSION + '_' + OPENPEDCAN_VERSION + '.xlsx'\n",
    "\n",
    "# Pediatric Cancer Data Navigation\n",
    "PCDN_PATH = 'data/processed/pcdn/' + OT_VERSION + '_' + OPENPEDCAN_VERSION + '/'\n",
    "PCDN_JSON = PCDN_PATH + 'chopDataNavigationTable.json'\n",
    "PCDN_JSONL = PCDN_PATH + 'jsonl_files'\n",
    "PCDN_JSONL_TEMP = PCDN_JSONL + '/'\n",
    "PCDN_JSONL_FILENAMES = 'pcdn_part_{0:04d}.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_files_to_df(path:str, filetype:str='*.json'):\n",
    "    \"\"\"\n",
    "    Load multiple identically-structured jsonl files within a local folder \n",
    "    into a single dataframe. Useful for OpenTargets FTP downloads.\n",
    "\n",
    "    :param path: Relative filepath to the folder containing the jsonl files.\n",
    "    :param filetype: Filetype suffix of files to include. default '*.json'\n",
    "    \"\"\"\n",
    "    \n",
    "    # OT uses 'json' extension for 'jsonl' files\n",
    "    fullPath = path + filetype\n",
    "\n",
    "    # Create list of all files within path folder\n",
    "    files = glob.glob(fullPath)\n",
    "\n",
    "    # Build df by combining all files in path folder\n",
    "    df = pd.concat(\n",
    "        (pd.read_json(f, orient='records', lines=True)\n",
    "        for f in files))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OT files as dataframes\n",
    "ot_asscOverallDirect = load_jsonl_files_to_df(OT_ASSC_OVERALLDIRECT_PATH)\n",
    "ot_asscOverallIndirect = load_jsonl_files_to_df(OT_ASSC_OVERALLINDIRECT_PATH)\n",
    "ot_diseases = load_jsonl_files_to_df(OT_DISEASES_PATH)\n",
    "ot_targets = load_jsonl_files_to_df(OT_TARGETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CHoP files as dataframes\n",
    "cnv = pd.read_json(CNV_PATH, orient='records', lines=True)\n",
    "snvGene = pd.read_json(SNVGENE_PATH, orient='records', lines=True)\n",
    "snv = pd.read_json(SNV_PATH, orient='records', lines=True)\n",
    "fusionGene = pd.read_json(FUSIONGENE_PATH, orient='records', lines=True)\n",
    "fusion = pd.read_json(FUSION_PATH, orient='records', lines=True)\n",
    "\n",
    "tpmGene = pd.read_json(TPMGENE_PATH, orient='records', lines=True)\n",
    "tpmGroup = pd.read_json(TPMGROUP_PATH, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PMTL as dataframes\n",
    "pmtl_df = pd.read_json(PMTL_PATH, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of priorities for testing as dataframes\n",
    "priority_targets = pd.read_csv(PRIORITY_TARGETS_PATH)\n",
    "priority_diseases = pd.read_csv(PRIORITY_DISEASES_PATH)\n",
    "priority_evidences = pd.read_csv(PRIORITY_EVIDENCES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify OT Target and Disease datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns except for ids and names\n",
    "ot_targets = ot_targets.loc[:, ['id', 'approvedSymbol']]\n",
    "ot_diseases = ot_diseases.loc[:, ['id', 'name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat CHoP TPM files for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to rename\n",
    "tpmColRenameDict = {\n",
    "    'Gene_Ensembl_ID': 'targetFromSourceId',\n",
    "    'EFO': 'diseaseFromSourceMappedId'\n",
    "}\n",
    "\n",
    "# Rename columns and add datasourceId column for each file\n",
    "tpmGene.rename(columns=tpmColRenameDict, inplace=True)\n",
    "tpmGene['datasourceId'] = 'chop_tpm_genewise_expression'\n",
    "\n",
    "tpmGroup.rename(columns=tpmColRenameDict, inplace=True)\n",
    "tpmGroup['datasourceId'] = 'chop_tpm_groupwise_expression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean IDs within CHoP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chop_targets(df:pd.DataFrame, ot_targets:pd.DataFrame=ot_targets):\n",
    "    \"\"\" Remove rows of evidence that contain blank or incompatible Target IDs.\n",
    "    These represent values that will not load into the MTP database. \n",
    "    \n",
    "    :param df: Dataframe of CHoP evidence file\n",
    "    :param ot_targets: Dataframe of Open Targets target database\n",
    "    \"\"\"\n",
    "\n",
    "    # Note any rows with blank target IDs\n",
    "    blankEvidences = len(df[df['targetFromSourceId'] == ''])\n",
    "    blankTargets = df[df['targetFromSourceId'] == '']['targetFromSourceId'].nunique()\n",
    "    print(f\"    {blankEvidences} evidences across {blankTargets} blank target IDs removed from {df.datasourceId[0]}\")\n",
    "\n",
    "    # Drop any rows with blank target IDs\n",
    "    df.drop(df[df['targetFromSourceId'] == ''].index, inplace=True)\n",
    "\n",
    "\n",
    "    # Enrich chop df with OT target ids and symbols\n",
    "    df1 = pd.merge(\n",
    "        df, ot_targets, how='left', left_on='targetFromSourceId', right_on='id').rename(\n",
    "        columns={'id':'otTargetId', 'approvedSymbol':'otSymbol'})\n",
    "\n",
    "    # Note any rows with target IDs not found within OT database\n",
    "    invalidEvidences = len(df1[df1['otTargetId'].isna()])\n",
    "    invalidTargets = df1[df1['otTargetId'].isna()]['targetFromSourceId'].nunique()\n",
    "    print(f\"    {invalidEvidences} evidences across {invalidTargets} invalid target IDs removed from {df.datasourceId[0]}\")\n",
    "\n",
    "    # Drop any rows with target IDs not found within OT database\n",
    "    df2 = df1[df1['otTargetId'].notnull()]\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chop_diseases(df:pd.DataFrame, ot_diseases:pd.DataFrame=ot_diseases):\n",
    "    \"\"\" Remove rows of evidence that contain blank or incompatible Disease IDs.\n",
    "    These represent values that will not load into the MTP database. \n",
    "    \n",
    "    :param df: Dataframe of CHoP evidence file\n",
    "    :param ot_diseases: Dataframe of Open Targets disease database\n",
    "    \"\"\"\n",
    "\n",
    "    # Note any rows with blank disease IDs\n",
    "    blankEvidences = len(df[df['diseaseFromSourceMappedId'] == ''])\n",
    "    blankDiseases = df[df['diseaseFromSourceMappedId'] == '']['diseaseFromSourceMappedId'].nunique()\n",
    "    print(f\"    {blankEvidences} evidences across {blankDiseases} blank disease IDs removed from {df.datasourceId[0]}\")\n",
    "\n",
    "    # Drop any rows with blank disease IDs\n",
    "    df.drop(df[df['diseaseFromSourceMappedId'] == ''].index, inplace=True)\n",
    "\n",
    "\n",
    "    # Enrich chop df with OT disease ids and symbols\n",
    "    df1 = pd.merge(\n",
    "        df, ot_diseases, how='left', left_on='diseaseFromSourceMappedId', right_on='id').rename(\n",
    "        columns={'id':'otDiseaseId', 'name':'otDiseaseName'})\n",
    "\n",
    "    # Note any rows with disease IDs not found within OT database\n",
    "    invalidEvidences = len(df1[df1['otDiseaseId'].isna()])\n",
    "    invalidDiseases = df1[df1['otDiseaseId'].isna()]['diseaseFromSourceMappedId'].nunique()\n",
    "    print(f\"    {invalidEvidences} evidences across {invalidDiseases} invalid disease IDs removed from {df.datasourceId[0]}\")\n",
    "\n",
    "    # Drop any rows with disease IDs not found within OT database\n",
    "    df2 = df1[df1['otDiseaseId'].notnull()]\n",
    "\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_cleaning_functions(df:pd.DataFrame, ot_targets:pd.DataFrame=ot_targets, ot_diseases:pd.DataFrame=ot_diseases):\n",
    "    \"\"\" Combines target and disease ID cleaning functions in series. \"\"\"\n",
    "\n",
    "    print(df.datasourceId[0], '\\n    Start length:', len(df))\n",
    "\n",
    "    df1 = clean_chop_targets(df)\n",
    "    df2 = clean_chop_diseases(df1)\n",
    "    \n",
    "    print('    End length:', len(df2), '\\n---')\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run each CHoP df through the cleaning functions defined above\n",
    "cnv_clean = chop_cleaning_functions(cnv)\n",
    "snvGene_clean = chop_cleaning_functions(snvGene)\n",
    "snv_clean = chop_cleaning_functions(snv)\n",
    "fusion_clean = chop_cleaning_functions(fusion)\n",
    "fusionGene_clean = chop_cleaning_functions(fusionGene)\n",
    "\n",
    "tpmGene_clean = chop_cleaning_functions(tpmGene)\n",
    "tpmGroup_clean = chop_cleaning_functions(tpmGroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Target-Disease Evidence Dataframe Function\n",
    "Build a dataframe containing all of the pediatric cancer evidence in the format required for validation. Test cases will be subsets of this df, exported into Excel for automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_case_df(dfList:list, ot_targets:pd.DataFrame=ot_targets, ot_diseases:pd.DataFrame=ot_diseases):\n",
    "    \"\"\" Build and format a dataframe to use when generating target and evidence page tests.\n",
    "    Combine and transform a list of cleaned/preprocessed evidence dataframes.\n",
    "    \n",
    "    :param dfList: list of pandas DataFrames containing evidence\n",
    "    :param ot_targets: pandas DataFrame of Open Targets targets to use for reference\n",
    "    :param ot_diseases: pandas DataFrame of Open Targets diseases to use for reference\n",
    "    \"\"\"\n",
    "\n",
    "    # Create blank output to fill with each evidence df\n",
    "    dfCombined = pd.DataFrame()\n",
    "\n",
    "    # Iterate through list of evidence dataframes\n",
    "    for df in dfList:\n",
    "\n",
    "        # Group data by 5 columns and get evidence count\n",
    "        # All evidence must use identical column names/contents\n",
    "        df1 = df.groupby(\n",
    "            ['targetFromSourceId', \n",
    "            'Gene_symbol', \n",
    "            'diseaseFromSourceMappedId', \n",
    "            'Disease', \n",
    "            'datasourceId']\n",
    "            ).size().reset_index().rename(columns={0:'evidenceCount'})\n",
    "\n",
    "        # Add each formatted df into a single dataframe\n",
    "        dfCombined = pd.concat([dfCombined, df1], ignore_index=True)\n",
    "\n",
    "    # Pivot to organize datasources as columns showing evidence sums\n",
    "    df2 = dfCombined.pivot_table(\n",
    "            values='evidenceCount', \n",
    "            index=['targetFromSourceId','diseaseFromSourceMappedId'], \n",
    "            columns='datasourceId', \n",
    "            aggfunc=sum, fill_value=0\n",
    "            ).reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "    # Use target IDs to map canonical OT names for targets\n",
    "    df3 = pd.merge(df2, ot_targets, how='left', left_on='targetFromSourceId', right_on='id').rename(columns={'approvedSymbol':'targetNameOT'})\n",
    "    df3.drop(columns='id', inplace=True)\n",
    "\n",
    "    # Use disease IDs to map canonical OT names for diseases\n",
    "    df4 = pd.merge(df3, ot_diseases, how='left', left_on='diseaseFromSourceMappedId', right_on='id').rename(columns={'name':'diseaseNameOT'})\n",
    "    df4.drop(columns='id', inplace=True)\n",
    "\n",
    "    # Rearrange output columns\n",
    "    df5 = df4[[\n",
    "                'targetFromSourceId',\n",
    "                'diseaseFromSourceMappedId',\n",
    "                'targetNameOT',\n",
    "                'diseaseNameOT',\n",
    "                'chop_gene_level_snv',\n",
    "                'chop_variant_level_snv',\n",
    "                'chop_gene_level_cnv',\n",
    "                'chop_putative_oncogene_fused_gene',\n",
    "                'chop_putative_oncogene_fusion',\n",
    "                'chop_tpm_groupwise_expression',\n",
    "                'chop_tpm_genewise_expression']]\n",
    "\n",
    "    return df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run function to combine evidence and build test case dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of clean dataframes for iteration\n",
    "dfList = [\n",
    "    cnv_clean,\n",
    "    snvGene_clean,\n",
    "    snv_clean,\n",
    "    fusion_clean,\n",
    "    fusionGene_clean,\n",
    "    tpmGene_clean,\n",
    "    tpmGroup_clean,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build test case\n",
    "testCase_df = build_test_case_df(dfList, ot_targets, ot_diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and export Pediatric Cancer Data Navigation table using the Test Case Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pcdn_df(df:pd.DataFrame=testCase_df):\n",
    "    \"\"\" Build the Pediatric Cancer Data Navigation table\n",
    "    by reformattign the test case dataframe. \n",
    "    \n",
    "    :param df: pandas dataFrame of combined and processed evidence\"\"\"\n",
    "\n",
    "    # Define labels and source columns for True/False summary columns\n",
    "    # This assumes that gene-level evidence presence matches variant-level\n",
    "    # presence in relevant data sources\n",
    "    pcdnSummaryDict = {\n",
    "    'SNV': 'chop_gene_level_snv',\n",
    "    'CNV': 'chop_gene_level_cnv',\n",
    "    'Fusion': 'chop_putative_oncogene_fused_gene',\n",
    "    'GeneExpression': 'chop_tpm_genewise_expression'\n",
    "    }\n",
    "\n",
    "    # Rename columns for clarity and to match input format\n",
    "    df1 = df.rename(columns={'targetNameOT':'Gene_symbol', 'diseaseNameOT':'Disease'})\n",
    "\n",
    "    # Create summary True/False columns for evidence presence\n",
    "    for label, col in pcdnSummaryDict.items():\n",
    "        df1[label] = np.where(df1[col] > 0, True, False)\n",
    "\n",
    "    # Keep only columns of interest\n",
    "    df2 = df1[\n",
    "        ['targetFromSourceId',\n",
    "        'diseaseFromSourceMappedId',\n",
    "        'Gene_symbol',\n",
    "        'Disease',\n",
    "        'SNV',\n",
    "        'CNV',\n",
    "        'Fusion',\n",
    "        'GeneExpression']]\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df_as_json(df:pd.DataFrame, outfile:str):\n",
    "    \"\"\" Export pandas dataframe as JSON file. Parsing using\n",
    "    json.dumps is needed to avoid extra backslashes otherwise\n",
    "    present if using only built-in pandas to_json().\n",
    "    \n",
    "    :param df: pandas dataframe to export\n",
    "    :param outfile: filename path for export\"\"\"\n",
    "    \n",
    "    # Make output directory if it doesn't exist\n",
    "    if os.path.exists(os.path.dirname(outfile)) == False:\n",
    "        os.makedirs(os.path.dirname(outfile))\n",
    "\n",
    "    # Load df as json string and parse\n",
    "    json_str = df.to_json(orient='records')\n",
    "    parsed = json.loads(json_str)\n",
    "\n",
    "    # Export to json filepath\n",
    "    with open(outfile, 'w') as json_file:\n",
    "        json_file.write(json.dumps(parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_df_as_jsonl_chunks(df:pd.DataFrame, \n",
    "                                directory:str, \n",
    "                                maxlines:int, \n",
    "                                fileformat:str):\n",
    "    \"\"\" Export pandas dataframe as many JSONL chunks for easier ETL.\n",
    "\n",
    "    :param df: pandas dataframe to export\n",
    "    :param directory: filepath of directory to hold exported jsonl\n",
    "    :param maxlines: int max number of jsonl lines per file\n",
    "    :param fileformat: name format for export files. \n",
    "        Must contain '{}' string for part number formatting\n",
    "    \"\"\"\n",
    "\n",
    "    # Make versioned directory if does not exist\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Load pandas df as json lines object\n",
    "    json_str = df.to_json(orient='records', lines=True)\n",
    "\n",
    "    # Load json lines as chunks with max lines of 50K per file\n",
    "    chunks = pd.read_json(json_str, orient='records', lines=True, chunksize=maxlines)\n",
    "\n",
    "    # Iterate through JSONL partitions to export as files. Show NaN values as blank\n",
    "    for label, chunk in enumerate(chunks):\n",
    "        dict_records = chunk.apply(lambda x: x.dropna()).to_dict('records')\n",
    "        jsonlData = ndjson.dumps(dict_records).encode('utf-8')\n",
    "        with open(directory+fileformat.format(label), 'wb') as file:\n",
    "            file.write(jsonlData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_md5(filename:str, suffix:str='_md5.txt', compression_type:str='zip'):\n",
    "    \"\"\" Create txt file containing md5sum of file. \n",
    "    \n",
    "    :param filename: path of file to compress\n",
    "    :param suffix: string to attach to end of md5.txt file\n",
    "    :param compression_type: file extension of filename\n",
    "    \"\"\"\n",
    "\n",
    "    compression_str = '.'+compression_type\n",
    "\n",
    "    with open(filename+compression_str, 'rb') as f:\n",
    "        contents = f.read() \n",
    "        md5_returned = hashlib.md5(contents).hexdigest()\n",
    "\n",
    "    with open(filename+suffix, 'w') as file:\n",
    "        file.write(md5_returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_temp_folder(directory:str):\n",
    "    \"\"\" Delete directory and all contents.\n",
    "\n",
    "    :param directory: path of directory to delete\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(directory)\n",
    "    except OSError as error:\n",
    "        print(f'Error: {directory}: {error.strerror}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_directory(filename, root, compression_type='zip'):\n",
    "    \"\"\"Compress and zip a file directory.\n",
    "    \n",
    "    :param filename: name of the directory to compress. This will\n",
    "                        also be used as filename for the output\n",
    "    :param root: parent directory containing the directory to compress\n",
    "    :param compression_type: compression type string, default 'zip'\n",
    "    \"\"\"\n",
    "\n",
    "    shutil.make_archive(filename, compression_type, root, filename.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_jsonl(df:pd.DataFrame,\n",
    "                    directory:str,\n",
    "                    maxlines:int,\n",
    "                    fileformat:str,\n",
    "                    filename:str,\n",
    "                    root:str,\n",
    "                    compression_type:str='zip',\n",
    "                    suffix:str='_md5.txt'):\n",
    "    \"\"\" Package a pandas dataframe into multiple JSONL files, compress,\n",
    "    and then get md5 checksum. \n",
    "    \n",
    "    :param df: pandas dataframe to export\n",
    "    :param directory: filepath of directory to hold exported jsonl\n",
    "    :param maxlines: int max number of jsonl lines per file\n",
    "    :param fileformat: name format for export files\n",
    "                    Must contain '{}' string for part number formatting\n",
    "    :param filename: name of the directory to compress. This will\n",
    "                    also be used as filename for the output\n",
    "    :param root: parent directory containing the directory to compress\n",
    "    :param compression_type: compression type string, default 'zip'\n",
    "    :param suffix: string to attach to end of md5.txt file\n",
    "    \"\"\"\n",
    "\n",
    "    export_df_as_jsonl_chunks(df, directory, maxlines, fileformat)\n",
    "    compress_directory(filename, root, compression_type=compression_type)\n",
    "    output_md5(filename, suffix=suffix, compression_type=compression_type)\n",
    "    clear_temp_folder(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buid PCDN\n",
    "pcdn_df = build_pcdn_df(testCase_df)\n",
    "\n",
    "# Export as single JSON\n",
    "export_df_as_json(pcdn_df, PCDN_JSON)\n",
    "\n",
    "# Export as multiple JSONL\n",
    "package_jsonl(df=pcdn_df, \n",
    "            directory=PCDN_JSONL_TEMP,\n",
    "            maxlines=3000,\n",
    "            fileformat=PCDN_JSONL_FILENAMES,\n",
    "            filename=PCDN_JSONL,\n",
    "            root=PCDN_PATH,\n",
    "            compression_type='zip',\n",
    "            suffix='_md5.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Test Case Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Target Associations (Direct Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_targetAssc(sampleSize:int,\n",
    "                            ot_asscOverallDirect:pd.DataFrame=ot_asscOverallDirect, \n",
    "                            ot_targets:pd.DataFrame=ot_targets, \n",
    "                            pmtl_df:pd.DataFrame=pmtl_df, \n",
    "                            priority_targets:pd.DataFrame=priority_targets,\n",
    "                            randomSeed:int=RANDOM_SEED):\n",
    "    \"\"\" Build test case df for Target Associations page. Not specific to new MTP data. \n",
    "    Note that until pediatric data is included in association scoring, MTP associations will\n",
    "    be identical to OT associations.\n",
    "\n",
    "    :param sampleSize: int number of random targets to include in test\n",
    "    :param ot_asscOverallDirect: pandas DataFrame of OpenTargets Overall Direct associations\n",
    "    :param ot_targets: pandas DataFrame of OpenTargets target names for reference\n",
    "    :param pmtl_df: pandas DataFrame of FDA PMTL\n",
    "    :param priority_targets: pandas DataFrame of targets to always include in test case\n",
    "    :param randomSeed: int seed for reproducible random results\"\"\"\n",
    "\n",
    "    # Group associations by targetId to mimic associations heatmap\n",
    "    df = ot_asscOverallDirect.groupby('targetId').size().reset_index()\n",
    "    \n",
    "    # Enrich associations with target names (OT Targets) and PMTL designations\n",
    "    df1 = df.merge(ot_targets, how='left', left_on='targetId', right_on='id').merge(\n",
    "                    pmtl_df[['ensemblID', 'designation']], how='left', left_on='targetId', right_on='ensemblID')\n",
    "    \n",
    "    # Rename columns\n",
    "    df2 = df1.rename(columns={\n",
    "        0:'diseaseCount',\n",
    "        'approvedSymbol':'targetNameOT',\n",
    "        'designation':'PMTLcode'})\n",
    "        \n",
    "    # Recast NaN PMTL as Unspecified\n",
    "    df2.fillna('Unspecified Target', inplace=True)\n",
    "\n",
    "    # Add suffix column\n",
    "    df2['suffixUrl'] = '/target/'+df2['targetId']+'/associations'\n",
    "\n",
    "    # Reorder columns and omit redundant\n",
    "    df3 = df2[['suffixUrl', 'targetId', 'targetNameOT', 'PMTLcode','diseaseCount']]\n",
    "\n",
    "    # Create subset df with priority targets and random sample of other targets\n",
    "    random.seed(randomSeed)\n",
    "    df4 = df3[\n",
    "            (df3['targetId'].isin(priority_targets['targetId'])) |\n",
    "            (df3['targetId'].isin(random.sample(df3['targetId'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Target Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_targetProfile(sampleSize:int, \n",
    "                                testCase_df:pd.DataFrame=testCase_df, \n",
    "                                priority_targets:pd.DataFrame=priority_targets,\n",
    "                                randomSeed:int=RANDOM_SEED):\n",
    "    \"\"\" Build test case df for Target Profile page. Should only include targets with\n",
    "    at least some new pediatric data. \n",
    "\n",
    "    :param sampleSize: int number of random targets to include in test case\n",
    "    :param testCase_df: pandas DataFrame of preprocessed evidence data\n",
    "    :param priority_targets: pandas DataFrame of targets to always include in test case\n",
    "    :param randomSeed: int seed for reproducible random results\"\"\"\n",
    "\n",
    "    df = testCase_df.groupby(['targetFromSourceId','targetNameOT']).sum().reset_index()\n",
    "\n",
    "    # Add TRUE/FALSE for presence of Gene Expression Widget (groupwise plot)\n",
    "    df['opcGeneExp_target'] = np.where(df['chop_tpm_groupwise_expression'] >0, 'TRUE', 'FALSE')\n",
    "\n",
    "    # List all datasourceIds to be grouped and considered Somatic Alterations with tab labels\n",
    "    somaticAltCols = {\n",
    "    'chop_gene_level_cnv':'cnvByGene',\n",
    "    'chop_gene_level_snv':'snvByGene',\n",
    "    'chop_putative_oncogene_fused_gene':'fusionByGene',\n",
    "    'chop_putative_oncogene_fusion':'fusion',\n",
    "    'chop_variant_level_snv':'snvByVariant'}\n",
    "\n",
    "    # Raname columns\n",
    "    df.rename(columns=somaticAltCols, inplace=True)\n",
    "    df.rename(columns={'targetFromSourceId':'targetId'}, inplace=True)\n",
    "\n",
    "    # Add TRUE/FALSE for presence of Somatic Alterations widget\n",
    "    df['opcSomaticAlt'] = np.where(df[somaticAltCols.values()].sum(axis=1) > 0, 'TRUE', 'FALSE')\n",
    "\n",
    "    # Add suffix column\n",
    "    df['suffixUrl'] ='/target/'+df['targetId']\n",
    "\n",
    "    # Rearrange columns and omit redundant\n",
    "    df1 = df[['suffixUrl', 'targetId', 'targetNameOT', 'opcGeneExp_target', 'opcSomaticAlt', 'snvByGene', 'snvByVariant', 'cnvByGene','fusionByGene','fusion']]\n",
    "\n",
    "    # Create subset df with priority targets and  random sample of other targets\n",
    "    random.seed(randomSeed)\n",
    "    df2 = df1[\n",
    "            (df1['targetId'].isin(priority_targets['targetId'])) |\n",
    "            (df1['targetId'].isin(random.sample(df1['targetId'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Disease Associations (Indirect Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_diseaseAssc(sampleSize:int,\n",
    "                            ot_asscOverallIndirect:pd.DataFrame=ot_asscOverallIndirect, \n",
    "                            ot_diseases:pd.DataFrame=ot_diseases,\n",
    "                            priority_diseases:pd.DataFrame=priority_diseases,\n",
    "                            randomSeed:int=RANDOM_SEED):\n",
    "    \"\"\" Build test case df for Target Associations page. Not specific to new MTP data. \n",
    "    Note that until pediatric data is included in association scoring, MTP associations will\n",
    "    be identical to OT associations.\n",
    "\n",
    "    :param sampleSize: int number of random diseases to include in test\n",
    "    :param ot_asscOverallIndirect: pandas DataFrame of OpenTargets Overall Indirect associations\n",
    "    :param ot_diseases: pandas DataFrame of OpenTargets disease names for reference\n",
    "    :param priority_diseases: pandas DataFrame of diseases to always include in test case\n",
    "    :param randomSeed: int seed for reproducible random results\n",
    "    \"\"\"\n",
    "\n",
    "    # Group associations by targetId to mimic associations heatmap\n",
    "    df = ot_asscOverallIndirect.groupby('diseaseId').size().reset_index()\n",
    "    \n",
    "    # Enrich associations with target names (OT Targets) and PMTL designations\n",
    "    df1 = df.merge(ot_diseases, how='left', left_on='diseaseId', right_on='id')\n",
    "    \n",
    "    # Rename columns\n",
    "    df2 = df1.rename(columns={\n",
    "        0:'targetCount',\n",
    "        'name':'diseaseNameOT'})\n",
    "\n",
    "    # Add suffix column\n",
    "    df2['suffixUrl'] = '/disease/'+df2['diseaseId']+'/associations'\n",
    "\n",
    "    # Reorder columns and omit redundant\n",
    "    df3 = df2[['suffixUrl', 'diseaseId', 'diseaseNameOT','targetCount']]\n",
    "\n",
    "    # Create subset df with priority targets and random sample of other targets\n",
    "    random.seed(randomSeed)\n",
    "    df4 = df3[\n",
    "            (df3['diseaseId'].isin(priority_diseases['diseaseId'])) |\n",
    "            (df3['diseaseId'].isin(random.sample(df3['diseaseId'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Evidence Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_evidence(sampleSize:int, \n",
    "                            testCase_df:pd.DataFrame=testCase_df, \n",
    "                            priority_evidences:pd.DataFrame=priority_evidences,\n",
    "                            randomSeed:int=RANDOM_SEED):\n",
    "    \"\"\" Build test case df for Evidence page. Should only include target-disease\n",
    "    evidence with at least some new pediatric data. \n",
    "\n",
    "    :param sampleSize: int number of random evidence combinations to include in test case\n",
    "    :param testCase_df: pandas DataFrame of preprocessed evidence data\n",
    "    :param priority_evidences: pandas DataFrame of evudebces to always include in test case\n",
    "    :param randomSeed: int seed for reproducible random results\"\"\"\n",
    "\n",
    "    # Build subset of testCase df using only priority evidences\n",
    "    priorityEvidence = pd.merge(priority_evidences[['targetId','diseaseId']], testCase_df, how='left', \n",
    "        left_on=['targetId','diseaseId'], right_on=['targetFromSourceId','diseaseFromSourceMappedId'])\n",
    "    priorityEvidence.drop(columns=['targetId','diseaseId'], inplace=True)\n",
    "\n",
    "    # Build subset of testCase df using random sample of evidence combinations\n",
    "    random.seed(randomSeed)\n",
    "    sampleEvidence = testCase_df.groupby(['targetFromSourceId', 'diseaseFromSourceMappedId']).size().reset_index().sample(sampleSize)\n",
    "    sampleEvidence.drop(columns=0, inplace=True)\n",
    "    sampleEvidenceDetails = pd.merge(sampleEvidence, testCase_df, how='left', on=['targetFromSourceId', 'diseaseFromSourceMappedId'])\n",
    "\n",
    "    # Concat priority and random subset dfs\n",
    "    df = pd.concat([priorityEvidence, sampleEvidenceDetails], ignore_index=True)\n",
    "\n",
    "    # Add TRUE/FALSE for presence of Gene Expression Widget (genewise plot)\n",
    "    df['opcGeneExp_evidence'] = np.where(df['chop_tpm_genewise_expression'] >0, 'TRUE', 'FALSE')\n",
    "\n",
    "    # List all datasourceIds to be grouped and considered Somatic Alterations with tab labels\n",
    "    somaticAltCols = {\n",
    "    'chop_gene_level_cnv':'cnvByGene',\n",
    "    'chop_gene_level_snv':'snvByGene',\n",
    "    'chop_putative_oncogene_fused_gene':'fusionByGene',\n",
    "    'chop_putative_oncogene_fusion':'fusion',\n",
    "    'chop_variant_level_snv':'snvByVariant'}\n",
    "\n",
    "    # Rename columns\n",
    "    df.rename(columns=somaticAltCols, inplace=True)\n",
    "    df.rename(columns={'targetFromSourceId':'targetId', 'diseaseFromSourceMappedId':'diseaseId'}, inplace=True)\n",
    "\n",
    "    # Add TRUE/FALSE for presence of Somatic Alterations widget\n",
    "    df['opcSomaticAlt'] = np.where(df[somaticAltCols.values()].sum(axis=1) > 0, 'TRUE', 'FALSE')\n",
    "\n",
    "    # Add suffix column\n",
    "    df['suffixUrl'] ='/evidence/'+df['targetId']+'/'+df['diseaseId']\n",
    "\n",
    "    # Rearrange columns and omit redundant\n",
    "    df1 = df[['suffixUrl', 'targetId', 'diseaseId', 'targetNameOT', 'diseaseNameOT', 'opcGeneExp_evidence', 'opcSomaticAlt', 'snvByGene', 'snvByVariant', 'cnvByGene','fusionByGene','fusion']]\n",
    "\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Pediatric Cancer Data Navigation (PCDN) by Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_pcdnGene(sampleSize:int, \n",
    "                        pcdn_df:pd.DataFrame=pcdn_df, \n",
    "                        priority_targets:pd.DataFrame=priority_targets,\n",
    "                        randomSeed:int=RANDOM_SEED):\n",
    "    \"\"\" Build test case df for PCDN page, gene search. Should only include \n",
    "    targets contained within the PCDN data (and therefore new pediatric data). \n",
    "\n",
    "    :param sampleSize: int number of random targets to include in test case\n",
    "    :param pcdn_df: pandas DataFrame of preprocessed Pediatric Cancer Data Navigation page\n",
    "    :param priority_targets: pandas DataFrame of targets to always include in test case\n",
    "    :param randomSeed: int seed for reproducible random results\"\"\"\n",
    "\n",
    "    # Build subset of the PCDN df using priority targets and random sample of other targets\n",
    "    random.seed(randomSeed)\n",
    "    df = pcdn_df[\n",
    "        (pcdn_df['Gene_symbol'].isin(priority_targets['symbol'])) |\n",
    "        (pcdn_df['Gene_symbol'].isin(random.sample(pcdn_df['Gene_symbol'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    # Group subset by gene symbol to get resulting evidence count\n",
    "    df1 = df.groupby('Gene_symbol').size().reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    df1.rename(columns={0:'evidenceResults', 'Gene_symbol':'name'}, inplace=True)\n",
    "\n",
    "    # Add suffix and category columns\n",
    "    df1['suffixUrl'] = '/pediatric-cancer-data-navigation'\n",
    "    df1['category'] = 'target'\n",
    "\n",
    "    # Rearrange columns and omit redundant\n",
    "    df2 = df1[['suffixUrl', 'category', 'name', 'evidenceResults']]\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Pediatric Cancer Data Navigation (PCDN) by Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_pcdnDisease(sampleSize:int, \n",
    "                        maxResults:int=10000,\n",
    "                        pcdn_df:pd.DataFrame=pcdn_df, \n",
    "                        priority_diseases:pd.DataFrame=priority_diseases,\n",
    "                        randomSeed:int=RANDOM_SEED):\n",
    "    \"\"\" Build test case df for PCDN page, disease search. Should only include \n",
    "    diseases contained within the PCDN data (and therefore new pediatric data). \n",
    "\n",
    "    :param sampleSize: int number of random diseases to include in test case\n",
    "    :param maxResults: int maximum count of evidence results. Default is 10,000 to match MTP\n",
    "    :param pcdn_df: pandas DataFrame of preprocessed Pediatric Cancer Data Navigation page\n",
    "    :param priority_diseases: pandas DataFrame of diseases to always include in test case\n",
    "    :param randomSeed: int seed for reproducible random results\"\"\"\n",
    "\n",
    "    # Build subset of the PCDN df using priority diseases and random sample of other diseases\n",
    "    random.seed(randomSeed)\n",
    "    df = pcdn_df[\n",
    "        (pcdn_df['Disease'].isin(priority_diseases['name'])) |\n",
    "        (pcdn_df['Disease'].isin(random.sample(pcdn_df['Disease'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    # Group subset by gene symbol to get resulting evidence count\n",
    "    df1 = df.groupby('Disease').size().reset_index().rename(columns={0:'fullResults'})\n",
    "\n",
    "    # Cap number of results at a maximum (default 10,000) to match site functionality\n",
    "    df1['evidenceResults'] = np.where(df1['fullResults'] > maxResults, maxResults, df1['fullResults'])\n",
    "\n",
    "    # Rename columns\n",
    "    df1.rename(columns={'Disease':'name'}, inplace=True)\n",
    "\n",
    "    # Add suffix and category columns\n",
    "    df1['suffixUrl'] = '/pediatric-cancer-data-navigation'\n",
    "    df1['category'] = 'disease'\n",
    "\n",
    "    # Rearrange columns and omit redundant\n",
    "    df2 = df1[['suffixUrl', 'category', 'name', 'evidenceResults']]\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Pediatric Molecular Targets Lists (PMTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_pmtl(pmtl_df:pd.DataFrame=pmtl_df):\n",
    "    \"\"\" Build test case df for FDA PMTL page.\n",
    "\n",
    "    :param pmtl_df: pandas DataFrame of the computable FDA PMTL\"\"\"\n",
    "\n",
    "    df = pmtl_df.groupby('designation').size().reset_index()\n",
    "\n",
    "    df['suffixUrl'] = '/fda-pmtl'\n",
    "    df['category'] = 'designation'\n",
    "\n",
    "    df.rename(columns={0:'count', 'designation':'categoryValue'}, inplace=True)\n",
    "\n",
    "    df1 = df[['suffixUrl', 'category', 'categoryValue', 'count']]\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test case functions to build dataframes for excel export\n",
    "targetAssc = build_testCase_targetAssc(10)\n",
    "targetProfile = build_testCase_targetProfile(10)\n",
    "diseaseAssc = build_testCase_diseaseAssc(10)\n",
    "evidence = build_testCase_evidence(15)\n",
    "pcdnGene = build_testCase_pcdnGene(10)\n",
    "pcdnDisease = build_testCase_pcdnDisease(10)\n",
    "pmtl = build_testCase_pmtl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Test Cases to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build df with test generation metadata\n",
    "sourceData = pd.DataFrame({\n",
    "    'Open Targets Version':OT_VERSION, \n",
    "    'CHoP OpenPedCan Version': OPENPEDCAN_VERSION, \n",
    "    'PMTL Version':PMTL_VERSION,\n",
    "    'Test Case Generation Date':pd.Timestamp.now(),\n",
    "    'Reproducible Random Seed':RANDOM_SEED\n",
    "    }.items(),\n",
    "    columns=['MTP DV3 TEST CASES FOR AUTOMATION', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and name test case dfs for export\n",
    "outputDict = {\n",
    "    'sourceData': sourceData,\n",
    "    'targetAssc': targetAssc,\n",
    "    'targetProfile': targetProfile,\n",
    "    'diseaseAssc': diseaseAssc,\n",
    "    'evidence': evidence,\n",
    "    'pcdnGene': pcdnGene,\n",
    "    'pcdnDisease': pcdnDisease,\n",
    "    'pmtl': pmtl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_test_cases_as_excel(outputDict:dict, outfile:str=XLSX_OUTPUT):\n",
    "    \"\"\" Build and format an Excel file containing test cases for automation.\n",
    "    \n",
    "    :param outfile: filepath for Excel output file\n",
    "    :param outputDict: dict of test cases to export as Excel sheets\"\"\"\n",
    "\n",
    "    # Create writer using XlsxWriter as the engine\n",
    "    writer = pd.ExcelWriter(outfile, engine='xlsxwriter')\n",
    "\n",
    "    # Write each test case df defined in outputDict to a sheet\n",
    "    for sheetname, df in outputDict.items():\n",
    "        df.to_excel(writer, sheet_name=sheetname, index=False)\n",
    "    \n",
    "    # Format width of (descriptive) first sheet columns for readability\n",
    "    writer.sheets[list(outputDict.keys())[0]].set_column(0, 0, 40)\n",
    "    writer.sheets[list(outputDict.keys())[0]].set_column(1, 1, 20)\n",
    "\n",
    "    # Save and close excel writer\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run export function\n",
    "export_test_cases_as_excel(outputDict, XLSX_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "431f20539060e4195af057caf518edb196c7ace9bef336047b9965dbe49805af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
