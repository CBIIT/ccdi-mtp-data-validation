{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation 3:  Verify that data appears as expected within the MTP UI\n",
    "2022-10-28 ZD  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "### \"Does the MTP UI match the MTP database?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "This validation will test “completeness and accuracy of data loaded into the platform” and follow MTP Data Validations 1&2. It will compare the data displayed within the platform GUI (after loading) to the expected values within the data (before loading). Automated scripts will pull test cases from the data that can be fed into platform testing automations to check displays for completeness and accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope\n",
    "DV3 will focus on displays within the platform that relate to new pediatric data, including those that happen to incorporate Open Targets (OT) data. New pediatric data includes the Food and Drug Administration’s Pediatric Molecular Target Lists (FDA PMTL); the much larger collection of evidence data provided by the Children’s Hospital of Philadelphia (CHoP); and derived summary tables, such as the Pediatric Cancer Data Navigation (PCDN) page. It will not validate or test displays that only include OT data without pediatric data.  \n",
    "\n",
    "The testing within DV3 will use sampling (spot-checking) methods, though scalability to meet automation capacity will be a design goal. Samples tested will include a set of defined high-profile genes and diseases that we expect will garner an abundance of user attention. We will also include a random sampling of genes and diseases (associated with CHoP data) to expand testing scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case Overview\n",
    "\n",
    "Testable values for each test case will be contained in a tab within the output Excel\n",
    "\n",
    "1. Target Association\n",
    "    - Count of associated diseases\n",
    "    - PMTL annotation\n",
    "2. Target Profile Page\n",
    "    - Somatic Alterations widget\n",
    "        - Status\n",
    "        - Row count of each of 5 tabs\n",
    "    - Gene Expression widget\n",
    "        - Status\n",
    "3. Disease Association\n",
    "    - Count of associated targets\n",
    "4. Evidence Page\n",
    "    - Somatic Alterations widget\n",
    "        - Status\n",
    "        - Row count of each of 5 tabs\n",
    "    - Gene Expression widget\n",
    "        - Status   \n",
    "5. Pediatric Cancer Data Navigation (PCDN) Page\n",
    "    - Row count of resulting evidence pages when searching for target or disease\n",
    "6. Pediatric Molecular Targets List (PMTL) Page\n",
    "    - Row count of Relevant and Non-Relevant targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and define relative paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORE VERSIONS\n",
    "OT_VERSION = '22.04'\n",
    "OPENPEDCAN_VERSION = 'v10.0'\n",
    "PMTL_VERSION = 'v3.0'\n",
    "\n",
    "# --------\n",
    "\n",
    "# INPUTS\n",
    "\n",
    "# Data from Open Targets\n",
    "OT_PATH = 'data/external/opentargets/platform/' + OT_VERSION + '/output/etl/json/'\n",
    "\n",
    "OT_ASSC_OVERALLDIRECT_PATH = OT_PATH + 'associationByOverallDirect/'\n",
    "OT_ASSC_OVERALLINDIRECT_PATH = OT_PATH + 'associationByOverallIndirect/'\n",
    "OT_DISEASES_PATH = OT_PATH + 'diseases/'\n",
    "OT_TARGETS_PATH = OT_PATH + 'targets/'\n",
    "\n",
    "# Data from CHoP\n",
    "CHOP_PATH = 'data/raw/OpenPedCan_' + OPENPEDCAN_VERSION + '/'\n",
    "\n",
    "# CHoP: Somatic Alterations\n",
    "CNV_PATH = CHOP_PATH + 'gene-level-cnv-consensus-annotated-mut-freq.jsonl.gz'\n",
    "SNVGENE_PATH = CHOP_PATH + 'gene-level-snv-consensus-annotated-mut-freq.jsonl.gz'\n",
    "SNV_PATH = CHOP_PATH + 'variant-level-snv-consensus-annotated-mut-freq.jsonl.gz'\n",
    "FUSIONGENE_PATH = CHOP_PATH + 'putative-oncogene-fused-gene-freq.jsonl.gz'\n",
    "FUSION_PATH = CHOP_PATH + 'putative-oncogene-fusion-freq.jsonl.gz'\n",
    "\n",
    "# CHoP: Gene Expression\n",
    "TPMGENE_PATH = CHOP_PATH + 'long_n_tpm_mean_sd_quantile_gene_wise_zscore.jsonl.gz'\n",
    "TPMGROUP_PATH = CHOP_PATH + 'long_n_tpm_mean_sd_quantile_group_wise_zscore.jsonl.gz'\n",
    "\n",
    "# PMTL and PCDN data\n",
    "PMTL_PATH = 'data/processed/pmtl_' + PMTL_VERSION + '.json'\n",
    "PCDN_PATH = 'data/processed/chopDataNavigationTable_' + OT_VERSION + '_' + OPENPEDCAN_VERSION + '.json'\n",
    "\n",
    "# Priority targets and diseases for test cases\n",
    "PRIORITY_PATH = 'data/processed/dv3_priority_tests/'\n",
    "PRIORITY_TARGETS_PATH = PRIORITY_PATH + 'targets.csv'\n",
    "PRIORITY_DISEASES_PATH = PRIORITY_PATH + 'diseases.csv'\n",
    "PRIORITY_EVIDENCES_PATH = PRIORITY_PATH + 'evidences.csv'\n",
    "\n",
    "# --------\n",
    "\n",
    "# OUTPUTS\n",
    "XLSX_OUTPUT = 'MTP_DataValidation_InputFile.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_files_to_df(path:str, filetype:str='*.json'):\n",
    "    \"\"\"\n",
    "    Load multiple identically-structured jsonl files within a local folder \n",
    "    into a single dataframe. Useful for OpenTargets FTP downloads.\n",
    "\n",
    "    :param path: Relative filepath to the folder containing the jsonl files.\n",
    "    :param filetype: Filetype suffix of files to include. default '*.json'\n",
    "    \"\"\"\n",
    "    \n",
    "    # OT uses 'json' extension for 'jsonl' files\n",
    "    fullPath = path + filetype\n",
    "\n",
    "    # Create list of all files within path folder\n",
    "    files = glob.glob(fullPath)\n",
    "\n",
    "    # Build df by combining all files in path folder\n",
    "    df = pd.concat(\n",
    "        (pd.read_json(f, orient='records', lines=True)\n",
    "        for f in files))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OT files as dataframes\n",
    "ot_asscOverallDirect = load_jsonl_files_to_df(OT_ASSC_OVERALLDIRECT_PATH)\n",
    "ot_asscOverallIndirect = load_jsonl_files_to_df(OT_ASSC_OVERALLINDIRECT_PATH)\n",
    "ot_diseases = load_jsonl_files_to_df(OT_DISEASES_PATH)\n",
    "ot_targets = load_jsonl_files_to_df(OT_TARGETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CHoP files as dataframes\n",
    "cnv = pd.read_json(CNV_PATH, orient='records', lines=True)\n",
    "snvGene = pd.read_json(SNVGENE_PATH, orient='records', lines=True)\n",
    "snv = pd.read_json(SNV_PATH, orient='records', lines=True)\n",
    "fusionGene = pd.read_json(FUSIONGENE_PATH, orient='records', lines=True)\n",
    "fusion = pd.read_json(FUSION_PATH, orient='records', lines=True)\n",
    "\n",
    "tpmGene = pd.read_json(TPMGENE_PATH, orient='records', lines=True)\n",
    "tpmGroup = pd.read_json(TPMGROUP_PATH, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PMTL and PCDN as dataframes\n",
    "pmtl_df = pd.read_json(PMTL_PATH, orient='records')\n",
    "pcdn_df = pd.read_json(PCDN_PATH, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of priorities for testing as dataframes\n",
    "priority_targets = pd.read_csv(PRIORITY_TARGETS_PATH)\n",
    "priority_diseases = pd.read_csv(PRIORITY_DISEASES_PATH)\n",
    "priority_evidences = pd.read_csv(PRIORITY_EVIDENCES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify OT Target and Disease datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns except for ids and names\n",
    "ot_targets = ot_targets.loc[:, ['id', 'approvedSymbol']]\n",
    "ot_diseases = ot_diseases.loc[:, ['id', 'name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat CHoP TPM files for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to rename\n",
    "tpmColRenameDict = {\n",
    "    'Gene_Ensembl_ID': 'targetFromSourceId',\n",
    "    'EFO': 'diseaseFromSourceMappedId'\n",
    "}\n",
    "\n",
    "# Rename columns and add datasourceId column for each file\n",
    "tpmGene.rename(columns=tpmColRenameDict, inplace=True)\n",
    "tpmGene['datasourceId'] = 'chop_tpm_genewise_expression'\n",
    "\n",
    "tpmGroup.rename(columns=tpmColRenameDict, inplace=True)\n",
    "tpmGroup['datasourceId'] = 'chop_tpm_groupwise_expression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean IDs within CHoP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chop_targets(df:pd.DataFrame, ot_targets:pd.DataFrame=ot_targets):\n",
    "    \"\"\" Remove rows of evidence that contain blank or incompatible Target IDs.\n",
    "    These represent values that will not load into the MTP database. \n",
    "    \n",
    "    :param df: Dataframe of CHoP evidence file\n",
    "    :param ot_targets: Dataframe of Open Targets target database\n",
    "    \"\"\"\n",
    "\n",
    "    # Note any rows with blank target IDs\n",
    "    blankEvidences = len(df[df['targetFromSourceId'] == ''])\n",
    "    blankTargets = df[df['targetFromSourceId'] == '']['targetFromSourceId'].nunique()\n",
    "    print(f\"    {blankEvidences} evidences across {blankTargets} blank target IDs removed from {df.datasourceId[0]}\")\n",
    "\n",
    "    # Drop any rows with blank target IDs\n",
    "    df.drop(df[df['targetFromSourceId'] == ''].index, inplace=True)\n",
    "\n",
    "\n",
    "    # Enrich chop df with OT target ids and symbols\n",
    "    df1 = pd.merge(\n",
    "        df, ot_targets, how='left', left_on='targetFromSourceId', right_on='id').rename(\n",
    "        columns={'id':'otTargetId', 'approvedSymbol':'otSymbol'})\n",
    "\n",
    "    # Note any rows with target IDs not found within OT database\n",
    "    invalidEvidences = len(df1[df1['otTargetId'].isna()])\n",
    "    invalidTargets = df1[df1['otTargetId'].isna()]['targetFromSourceId'].nunique()\n",
    "    print(f\"    {invalidEvidences} evidences across {invalidTargets} invalid target IDs removed from {df.datasourceId[0]}\")\n",
    "\n",
    "    # Drop any rows with target IDs not found within OT database\n",
    "    df2 = df1[df1['otTargetId'].notnull()]\n",
    "\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chop_diseases(df:pd.DataFrame, ot_diseases:pd.DataFrame=ot_diseases):\n",
    "    \"\"\" Remove rows of evidence that contain blank or incompatible Disease IDs.\n",
    "    These represent values that will not load into the MTP database. \n",
    "    \n",
    "    :param df: Dataframe of CHoP evidence file\n",
    "    :param ot_diseases: Dataframe of Open Targets disease database\n",
    "    \"\"\"\n",
    "\n",
    "    # Note any rows with blank disease IDs\n",
    "    blankEvidences = len(df[df['diseaseFromSourceMappedId'] == ''])\n",
    "    blankDiseases = df[df['diseaseFromSourceMappedId'] == '']['diseaseFromSourceMappedId'].nunique()\n",
    "    print(f\"    {blankEvidences} evidences across {blankDiseases} blank disease IDs removed from {df.datasourceId[0]}\")\n",
    "\n",
    "    # Drop any rows with blank disease IDs\n",
    "    df.drop(df[df['diseaseFromSourceMappedId'] == ''].index, inplace=True)\n",
    "\n",
    "\n",
    "    # Enrich chop df with OT disease ids and symbols\n",
    "    df1 = pd.merge(\n",
    "        df, ot_diseases, how='left', left_on='diseaseFromSourceMappedId', right_on='id').rename(\n",
    "        columns={'id':'otDiseaseId', 'name':'otDiseaseName'})\n",
    "\n",
    "    # Note any rows with disease IDs not found within OT database\n",
    "    invalidEvidences = len(df1[df1['otDiseaseId'].isna()])\n",
    "    invalidDiseases = df1[df1['otDiseaseId'].isna()]['diseaseFromSourceMappedId'].nunique()\n",
    "    print(f\"    {invalidEvidences} evidences across {invalidDiseases} invalid disease IDs removed from {df.datasourceId[0]}\")\n",
    "\n",
    "    # Drop any rows with disease IDs not found within OT database\n",
    "    df2 = df1[df1['otDiseaseId'].notnull()]\n",
    "\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_cleaning_functions(df:pd.DataFrame, ot_targets:pd.DataFrame=ot_targets, ot_diseases:pd.DataFrame=ot_diseases):\n",
    "    \"\"\" Combines target and disease ID cleaning functions in series. \"\"\"\n",
    "\n",
    "    print(df.datasourceId[0], '\\n    Start length:', len(df))\n",
    "\n",
    "    df1 = clean_chop_targets(df)\n",
    "    df2 = clean_chop_diseases(df1)\n",
    "    \n",
    "    print('    End length:', len(df2), '\\n---')\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chop_gene_level_cnv \n",
      "    Start length: 1505739\n",
      "    0 evidences across 0 blank target IDs removed from chop_gene_level_cnv\n",
      "    943 evidences across 22 invalid target IDs removed from chop_gene_level_cnv\n",
      "    0 evidences across 0 blank disease IDs removed from chop_gene_level_cnv\n",
      "    0 evidences across 0 invalid disease IDs removed from chop_gene_level_cnv\n",
      "    End length: 1504796 \n",
      "---\n",
      "chop_gene_level_snv \n",
      "    Start length: 102569\n",
      "    0 evidences across 0 blank target IDs removed from chop_gene_level_snv\n",
      "    121 evidences across 44 invalid target IDs removed from chop_gene_level_snv\n",
      "    42 evidences across 1 blank disease IDs removed from chop_gene_level_snv\n",
      "    0 evidences across 0 invalid disease IDs removed from chop_gene_level_snv\n",
      "    End length: 102406 \n",
      "---\n",
      "chop_variant_level_snv \n",
      "    Start length: 535622\n",
      "    0 evidences across 0 blank target IDs removed from chop_variant_level_snv\n",
      "    358 evidences across 44 invalid target IDs removed from chop_variant_level_snv\n",
      "    43 evidences across 1 blank disease IDs removed from chop_variant_level_snv\n",
      "    0 evidences across 0 invalid disease IDs removed from chop_variant_level_snv\n",
      "    End length: 535221 \n",
      "---\n",
      "chop_putative_oncogene_fusion \n",
      "    Start length: 69107\n",
      "    17 evidences across 1 blank target IDs removed from chop_putative_oncogene_fusion\n",
      "    281 evidences across 93 invalid target IDs removed from chop_putative_oncogene_fusion\n",
      "    27 evidences across 1 blank disease IDs removed from chop_putative_oncogene_fusion\n",
      "    0 evidences across 0 invalid disease IDs removed from chop_putative_oncogene_fusion\n",
      "    End length: 68782 \n",
      "---\n",
      "chop_putative_oncogene_fused_gene \n",
      "    Start length: 30754\n",
      "    11 evidences across 1 blank target IDs removed from chop_putative_oncogene_fused_gene\n",
      "    170 evidences across 93 invalid target IDs removed from chop_putative_oncogene_fused_gene\n",
      "    22 evidences across 1 blank disease IDs removed from chop_putative_oncogene_fused_gene\n",
      "    0 evidences across 0 invalid disease IDs removed from chop_putative_oncogene_fused_gene\n",
      "    End length: 30551 \n",
      "---\n",
      "chop_tpm_genewise_expression \n",
      "    Start length: 2803608\n",
      "    0 evidences across 0 blank target IDs removed from chop_tpm_genewise_expression\n",
      "    14832 evidences across 200 invalid target IDs removed from chop_tpm_genewise_expression\n",
      "    0 evidences across 0 blank disease IDs removed from chop_tpm_genewise_expression\n",
      "    0 evidences across 0 invalid disease IDs removed from chop_tpm_genewise_expression\n",
      "    End length: 2788776 \n",
      "---\n",
      "chop_tpm_groupwise_expression \n",
      "    Start length: 2803608\n",
      "    0 evidences across 0 blank target IDs removed from chop_tpm_groupwise_expression\n",
      "    14832 evidences across 200 invalid target IDs removed from chop_tpm_groupwise_expression\n",
      "    0 evidences across 0 blank disease IDs removed from chop_tpm_groupwise_expression\n",
      "    0 evidences across 0 invalid disease IDs removed from chop_tpm_groupwise_expression\n",
      "    End length: 2788776 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Run each CHoP df through the cleaning functions defined above\n",
    "cnv_clean = chop_cleaning_functions(cnv)\n",
    "snvGene_clean = chop_cleaning_functions(snvGene)\n",
    "snv_clean = chop_cleaning_functions(snv)\n",
    "fusion_clean = chop_cleaning_functions(fusion)\n",
    "fusionGene_clean = chop_cleaning_functions(fusionGene)\n",
    "\n",
    "tpmGene_clean = chop_cleaning_functions(tpmGene)\n",
    "tpmGroup_clean = chop_cleaning_functions(tpmGroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Target-Disease Evidence Dataframe Function\n",
    "Build a dataframe containing all of the pediatric cancer evidence in the format required for validation. Test cases will be subsets of this df, exported into Excel for automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_case_df(dfList:list=dfList, ot_targets:pd.DataFrame=ot_targets, ot_diseases:pd.DataFrame=ot_diseases):\n",
    "    \"\"\" Build and format a dataframe to use when generating target and evidence page tests.\n",
    "    Combine and transform a list of cleaned/preprocessed evidence dataframes.\n",
    "    \n",
    "    :param dfList: list of pandas DataFrames containing evidence\n",
    "    :param ot_targets: pandas DataFrame of Open Targets targets to use for reference\n",
    "    :param ot_diseases: pandas DataFrame of Open Targets diseases to use for reference\n",
    "    \"\"\"\n",
    "\n",
    "    # Create blank output to fill with each evidence df\n",
    "    dfCombined = pd.DataFrame()\n",
    "\n",
    "    # Iterate through list of evidence dataframes\n",
    "    for df in dfList:\n",
    "\n",
    "        # Group data by 5 columns and get evidence count\n",
    "        # All evidence must use identical column names/contents\n",
    "        df1 = df.groupby(\n",
    "            ['targetFromSourceId', \n",
    "            'Gene_symbol', \n",
    "            'diseaseFromSourceMappedId', \n",
    "            'Disease', \n",
    "            'datasourceId']\n",
    "            ).size().reset_index().rename(columns={0:'evidenceCount'})\n",
    "\n",
    "        # Add each formatted df into a single dataframe\n",
    "        dfCombined = pd.concat([dfCombined, df1], ignore_index=True)\n",
    "\n",
    "    # Pivot to organize datasources as columns showing evidence sums\n",
    "    df2 = dfCombined.pivot_table(\n",
    "            values='evidenceCount', \n",
    "            index=['targetFromSourceId','diseaseFromSourceMappedId'], \n",
    "            columns='datasourceId', \n",
    "            aggfunc=sum, fill_value=0\n",
    "            ).reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "    # Use target IDs to map canonical OT names for targets\n",
    "    df3 = pd.merge(df2, ot_targets, how='left', left_on='targetFromSourceId', right_on='id').rename(columns={'approvedSymbol':'targetNameOT'})\n",
    "    df3.drop(columns='id', inplace=True)\n",
    "\n",
    "    # Use disease IDs to map canonical OT names for diseases\n",
    "    df4 = pd.merge(df3, ot_diseases, how='left', left_on='diseaseFromSourceMappedId', right_on='id').rename(columns={'name':'diseaseNameOT'})\n",
    "    df4.drop(columns='id', inplace=True)\n",
    "\n",
    "    # Rearrange output columns\n",
    "    df5 = df4[[\n",
    "                'targetFromSourceId',\n",
    "                'diseaseFromSourceMappedId',\n",
    "                'targetNameOT',\n",
    "                'diseaseNameOT',\n",
    "                'chop_gene_level_snv',\n",
    "                'chop_variant_level_snv',\n",
    "                'chop_gene_level_cnv',\n",
    "                'chop_putative_oncogene_fused_gene',\n",
    "                'chop_putative_oncogene_fusion',\n",
    "                'chop_tpm_groupwise_expression',\n",
    "                'chop_tpm_genewise_expression']]\n",
    "\n",
    "    return df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run function to combine evidence and build test case dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of clean dataframes for iteration\n",
    "dfList = [\n",
    "    cnv_clean,\n",
    "    snvGene_clean,\n",
    "    snv_clean,\n",
    "    fusion_clean,\n",
    "    fusionGene_clean,\n",
    "    tpmGene_clean,\n",
    "    tpmGroup_clean,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCase_df = build_test_case_df(dfList, ot_targets, ot_diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Test Case Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Target Associations (Direct Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_targetAssc(sampleSize:int,\n",
    "                            ot_asscOverallDirect:pd.DataFrame=ot_asscOverallDirect, \n",
    "                            ot_targets:pd.DataFrame=ot_targets, \n",
    "                            pmtl_df:pd.DataFrame=pmtl_df, \n",
    "                            priority_targets:pd.DataFrame=priority_targets):\n",
    "    \"\"\" Build test case df for Target Associations page. Not specific to new MTP data. \n",
    "    Note that until pediatric data is included in association scoring, MTP associations will\n",
    "    be identical to OT associations.\n",
    "\n",
    "    :param sampleSize: int number of random targets to include in test\n",
    "    :param ot_asscOverallDirect: pandas DataFrame of OpenTargets Overall Direct associations\n",
    "    :param ot_targets: pandas DataFrame of OpenTargets target names for reference\n",
    "    :param pmtl_df: pandas DataFrame of FDA PMTL\n",
    "    :param priority_targets: pandas DataFrame of targets to always include in test case\"\"\"\n",
    "\n",
    "    # Group associations by targetId to mimic associations heatmap\n",
    "    df = ot_asscOverallDirect.groupby('targetId').size().reset_index()\n",
    "    \n",
    "    # Enrich associations with target names (OT Targets) and PMTL designations\n",
    "    df1 = df.merge(ot_targets, how='left', left_on='targetId', right_on='id').merge(\n",
    "                    pmtl_df[['ensemblID', 'designation']], how='left', left_on='targetId', right_on='ensemblID')\n",
    "    \n",
    "    # Rename columns\n",
    "    df2 = df1.rename(columns={\n",
    "        0:'diseaseCount',\n",
    "        'approvedSymbol':'targetNameOT',\n",
    "        'designation':'PMTLcode'})\n",
    "        \n",
    "    # Recast NaN PMTL as Unspecified\n",
    "    df2.fillna('Unspecified Target', inplace=True)\n",
    "\n",
    "    # Add suffix column\n",
    "    df2['suffixUrl'] = '/target/'+df2['targetId']+'/associations'\n",
    "\n",
    "    # Reorder columns and omit redundant\n",
    "    df3 = df2[['suffixUrl', 'targetId', 'targetNameOT', 'PMTLcode','diseaseCount']]\n",
    "\n",
    "    # Create subset df with priority targets and random sample of other targets\n",
    "    df4 = df3[\n",
    "            (df3['targetId'].isin(priority_targets['targetId'])) |\n",
    "            (df3['targetId'].isin(random.sample(df3['targetId'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Target Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_targetProfile(sampleSize:int, \n",
    "                                testCase_df:pd.DataFrame=testCase_df, \n",
    "                                priority_targets:pd.DataFrame=priority_targets):\n",
    "    \"\"\" Build test case df for Target Profile page. Should only include targets with\n",
    "    at least some new pediatric data. \n",
    "\n",
    "    :param sampleSize: int number of random targets to include in test case\n",
    "    :param testCase_df: pandas DataFrame of preprocessed evidence data\n",
    "    :param priority_targets: pandas DataFrame of targets to always include in test case\"\"\"\n",
    "\n",
    "    df = testCase_df.groupby(['targetFromSourceId','targetNameOT']).sum().reset_index()\n",
    "\n",
    "    # Add TRUE/FALSE for presence of Gene Expression Widget (groupwise plot)\n",
    "    df['opcGeneExp_target'] = np.where(df['chop_tpm_groupwise_expression'] >0, 'TRUE', 'FALSE')\n",
    "\n",
    "    # List all datasourceIds to be grouped and considered Somatic Alterations with tab labels\n",
    "    somaticAltCols = {\n",
    "    'chop_gene_level_cnv':'cnvByGene',\n",
    "    'chop_gene_level_snv':'snvByGene',\n",
    "    'chop_putative_oncogene_fused_gene':'fusionByGene',\n",
    "    'chop_putative_oncogene_fusion':'fusion',\n",
    "    'chop_variant_level_snv':'snvByVariant'}\n",
    "\n",
    "    # Raname columns\n",
    "    df.rename(columns=somaticAltCols, inplace=True)\n",
    "    df.rename(columns={'targetFromSourceId':'targetId'}, inplace=True)\n",
    "\n",
    "    # Add TRUE/FALSE for presence of Somatic Alterations widget\n",
    "    df['opcSomaticAlt'] = np.where(df[somaticAltCols.values()].sum(axis=1) > 0, 'TRUE', 'FALSE')\n",
    "\n",
    "    # Add suffix column\n",
    "    df['suffixUrl'] ='/target/'+df['targetId']\n",
    "\n",
    "    # Rearrange columns and omit redundant\n",
    "    df1 = df[['suffixUrl', 'targetId', 'targetNameOT', 'opcGeneExp_target', 'opcSomaticAlt', 'snvByGene', 'snvByVariant', 'cnvByGene','fusionByGene','fusion']]\n",
    "\n",
    "    # Create subset df with priority targets and random sample of other targets\n",
    "    df2 = df1[\n",
    "            (df1['targetId'].isin(priority_targets['targetId'])) |\n",
    "            (df1['targetId'].isin(random.sample(df1['targetId'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Disease Associations (Indirect Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_diseaseAssc(sampleSize:int,\n",
    "                            ot_asscOverallIndirect:pd.DataFrame=ot_asscOverallIndirect, \n",
    "                            ot_diseases:pd.DataFrame=ot_diseases,\n",
    "                            priority_diseases:pd.DataFrame=priority_diseases):\n",
    "    \"\"\" Build test case df for Target Associations page. Not specific to new MTP data. \n",
    "    Note that until pediatric data is included in association scoring, MTP associations will\n",
    "    be identical to OT associations.\n",
    "\n",
    "    :param sampleSize: int number of random diseases to include in test\n",
    "    :param ot_asscOverallIndirect: pandas DataFrame of OpenTargets Overall Indirect associations\n",
    "    :param ot_diseases: pandas DataFrame of OpenTargets disease names for reference\n",
    "    :param priority_diseases: pandas DataFrame of diseases to always include in test case\n",
    "    \"\"\"\n",
    "\n",
    "    # Group associations by targetId to mimic associations heatmap\n",
    "    df = ot_asscOverallIndirect.groupby('diseaseId').size().reset_index()\n",
    "    \n",
    "    # Enrich associations with target names (OT Targets) and PMTL designations\n",
    "    df1 = df.merge(ot_diseases, how='left', left_on='diseaseId', right_on='id')\n",
    "    \n",
    "    # Rename columns\n",
    "    df2 = df1.rename(columns={\n",
    "        0:'targetCount',\n",
    "        'name':'diseaseNameOT'})\n",
    "\n",
    "    # Add suffix column\n",
    "    df2['suffixUrl'] = '/disease/'+df2['diseaseId']+'/associations'\n",
    "\n",
    "    # Reorder columns and omit redundant\n",
    "    df3 = df2[['suffixUrl', 'diseaseId', 'diseaseNameOT','targetCount']]\n",
    "\n",
    "    # Create subset df with priority targets and random sample of other targets\n",
    "    df4 = df3[\n",
    "            (df3['diseaseId'].isin(priority_diseases['diseaseId'])) |\n",
    "            (df3['diseaseId'].isin(random.sample(df3['diseaseId'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Evidence Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_evidence(sampleSize:int, \n",
    "                            testCase_df:pd.DataFrame=testCase_df, \n",
    "                            priority_evidences:pd.DataFrame=priority_evidences):\n",
    "    \"\"\" Build test case df for Evidence page. Should only include target-disease\n",
    "    evidence with at least some new pediatric data. \n",
    "\n",
    "    :param sampleSize: int number of random evidence combinations to include in test case\n",
    "    :param testCase_df: pandas DataFrame of preprocessed evidence data\n",
    "    :param priority_evidences: pandas DataFrame of evudebces to always include in test case\"\"\"\n",
    "\n",
    "    # Build subset of testCase df using only priority evidences\n",
    "    priorityEvidence = pd.merge(priority_evidences[['targetId','diseaseId']], testCase_df, how='left', \n",
    "        left_on=['targetId','diseaseId'], right_on=['targetFromSourceId','diseaseFromSourceMappedId'])\n",
    "    priorityEvidence.drop(columns=['targetId','diseaseId'], inplace=True)\n",
    "\n",
    "    # Build subset of testCase df using random sample of evidence combinations\n",
    "    sampleEvidence = testCase_df.groupby(['targetFromSourceId', 'diseaseFromSourceMappedId']).size().reset_index().sample(sampleSize)\n",
    "    sampleEvidence.drop(columns=0, inplace=True)\n",
    "    sampleEvidenceDetails = pd.merge(sampleEvidence, testCase_df, how='left', on=['targetFromSourceId', 'diseaseFromSourceMappedId'])\n",
    "\n",
    "    # Concat priority and random subset dfs\n",
    "    df = pd.concat([priorityEvidence, sampleEvidenceDetails], ignore_index=True)\n",
    "\n",
    "    # Add TRUE/FALSE for presence of Gene Expression Widget (genewise plot)\n",
    "    df['opcGeneExp_evidence'] = np.where(df['chop_tpm_genewise_expression'] >0, 'TRUE', 'FALSE')\n",
    "\n",
    "    # List all datasourceIds to be grouped and considered Somatic Alterations with tab labels\n",
    "    somaticAltCols = {\n",
    "    'chop_gene_level_cnv':'cnvByGene',\n",
    "    'chop_gene_level_snv':'snvByGene',\n",
    "    'chop_putative_oncogene_fused_gene':'fusionByGene',\n",
    "    'chop_putative_oncogene_fusion':'fusion',\n",
    "    'chop_variant_level_snv':'snvByVariant'}\n",
    "\n",
    "    # Rename columns\n",
    "    df.rename(columns=somaticAltCols, inplace=True)\n",
    "    df.rename(columns={'targetFromSourceId':'targetId', 'diseaseFromSourceMappedId':'diseaseId'}, inplace=True)\n",
    "\n",
    "    # Add TRUE/FALSE for presence of Somatic Alterations widget\n",
    "    df['opcSomaticAlt'] = np.where(df[somaticAltCols.values()].sum(axis=1) > 0, 'TRUE', 'FALSE')\n",
    "\n",
    "    # Add suffix column\n",
    "    df['suffixUrl'] ='/evidence/'+df['targetId']+'/'+df['diseaseId']\n",
    "\n",
    "    # Rearrange columns and omit redundant\n",
    "    df1 = df[['suffixUrl', 'targetId', 'diseaseId', 'targetNameOT', 'diseaseNameOT', 'opcGeneExp_evidence', 'opcSomaticAlt', 'snvByGene', 'snvByVariant', 'cnvByGene','fusionByGene','fusion']]\n",
    "\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Pediatric Cancer Data Navigation (PCDN) by Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_pcdnGene(sampleSize:int, \n",
    "                        pcdn_df:pd.DataFrame=pcdn_df, \n",
    "                        priority_targets:pd.DataFrame=priority_targets):\n",
    "    \"\"\" Build test case df for PCDN page, gene search. Should only include \n",
    "    targets contained within the PCDN data (and therefore new pediatric data). \n",
    "\n",
    "    :param sampleSize: int number of random targets to include in test case\n",
    "    :param pcdn_df: pandas DataFrame of preprocessed Pediatric Cancer Data Navigation page\n",
    "    :param priority_targets: pandas DataFrame of targets to always include in test case\"\"\"\n",
    "\n",
    "    # Build subset of the PCDN df using priority targets and random sample of other targets\n",
    "    df = pcdn_df[\n",
    "        (pcdn_df['Gene_symbol'].isin(priority_targets['symbol'])) |\n",
    "        (pcdn_df['Gene_symbol'].isin(random.sample(pcdn_df['Gene_symbol'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    # Group subset by gene symbol to get resulting evidence count\n",
    "    df1 = df.groupby('Gene_symbol').size().reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    df1.rename(columns={0:'evidenceResults', 'Gene_symbol':'name'}, inplace=True)\n",
    "\n",
    "    # Add suffix and category columns\n",
    "    df1['suffixUrl'] = '/pediatric-cancer-data-navigation'\n",
    "    df1['category'] = 'target'\n",
    "\n",
    "    # Rearrange columns and omit redundant\n",
    "    df2 = df1[['suffixUrl', 'category', 'name', 'evidenceResults']]\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Pediatric Cancer Data Navigation (PCDN) by Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_pcdnDisease(sampleSize:int, \n",
    "                        maxResults:int=10000,\n",
    "                        pcdn_df:pd.DataFrame=pcdn_df, \n",
    "                        priority_diseases:pd.DataFrame=priority_diseases):\n",
    "    \"\"\" Build test case df for PCDN page, disease search. Should only include \n",
    "    diseases contained within the PCDN data (and therefore new pediatric data). \n",
    "\n",
    "    :param sampleSize: int number of random diseases to include in test case\n",
    "    :param maxResults: int maximum count of evidence results. Default is 10,000 to match MTP\n",
    "    :param pcdn_df: pandas DataFrame of preprocessed Pediatric Cancer Data Navigation page\n",
    "    :param priority_diseases: pandas DataFrame of diseases to always include in test case\"\"\"\n",
    "\n",
    "    # Build subset of the PCDN df using priority diseases and random sample of other diseases\n",
    "    df = pcdn_df[\n",
    "        (pcdn_df['Disease'].isin(priority_diseases['name'])) |\n",
    "        (pcdn_df['Disease'].isin(random.sample(pcdn_df['Disease'].unique().tolist(), sampleSize)))]\n",
    "\n",
    "    # Group subset by gene symbol to get resulting evidence count\n",
    "    df1 = df.groupby('Disease').size().reset_index().rename(columns={0:'fullResults'})\n",
    "\n",
    "    # Cap number of results at a maximum (default 10,000) to match site functionality\n",
    "    df1['evidenceResults'] = np.where(df1['fullResults'] > maxResults, maxResults, df1['fullResults'])\n",
    "\n",
    "    # Rename columns\n",
    "    df1.rename(columns={'Disease':'name'}, inplace=True)\n",
    "\n",
    "    # Add suffix and category columns\n",
    "    df1['suffixUrl'] = '/pediatric-cancer-data-navigation'\n",
    "    df1['category'] = 'disease'\n",
    "\n",
    "    # Rearrange columns and omit redundant\n",
    "    df2 = df1[['suffixUrl', 'category', 'name', 'evidenceResults']]\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: Pediatric Molecular Targets Lists (PMTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_testCase_pmtl(pmtl_df:pd.DataFrame=pmtl_df):\n",
    "    \"\"\" Build test case df for FDA PMTL page.\n",
    "\n",
    "    :param pmtl_df: pandas DataFrame of the computable FDA PMTL\"\"\"\n",
    "\n",
    "    df = pmtl_df.groupby('designation').size().reset_index()\n",
    "\n",
    "    df['suffixUrl'] = '/fda-pmtl'\n",
    "    df['category'] = 'designation'\n",
    "\n",
    "    df.rename(columns={0:'count', 'designation':'categoryValue'}, inplace=True)\n",
    "\n",
    "    df1 = df[['suffixUrl', 'category', 'categoryValue', 'count']]\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test case functions to build dataframes for excel export\n",
    "targetAssc = build_testCase_targetAssc(10)\n",
    "targetProfile = build_testCase_targetProfile(10)\n",
    "diseaseAssc = build_testCase_diseaseAssc(10)\n",
    "evidence = build_testCase_evidence(15)\n",
    "pcdnGene = build_testCase_pcdnGene(10)\n",
    "pcdnDisease = build_testCase_pcdnDisease(10)\n",
    "pmtl = build_testCase_pmtl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Test Cases to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build df with test generation metadata\n",
    "sourceData = pd.DataFrame({\n",
    "    'Test Case generation date':pd.Timestamp.now(),\n",
    "    'Open Targets Version':OT_VERSION, \n",
    "    'CHoP OpenPedCan Version': OPENPEDCAN_VERSION, \n",
    "    'PMTL Version':PMTL_VERSION}.items(),\n",
    "    columns=['MTP DV3 TEST CASES FOR AUTOMATION', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create writer using XlsxWriter as the engine\n",
    "writer = pd.ExcelWriter(XLSX_OUTPUT, engine='xlsxwriter')\n",
    "\n",
    "# Write each dataframe as a sheet to the excel file defined above\n",
    "sourceData.to_excel(writer, sheet_name='sourceData', index=False)\n",
    "targetAssc.to_excel(writer, sheet_name='targetAssc', index=False)\n",
    "targetProfile.to_excel(writer, sheet_name='targetProfile', index=False)\n",
    "diseaseAssc.to_excel(writer, sheet_name='diseaseAssc', index=False)\n",
    "evidence.to_excel(writer, sheet_name='evidence', index=False)\n",
    "pcdnGene.to_excel(writer, sheet_name='pcdnGene', index=False)\n",
    "pcdnDisease.to_excel(writer, sheet_name='pcdnDisease', index=False)\n",
    "pmtl.to_excel(writer, sheet_name='pmtl', index=False)\n",
    "\n",
    "# Save and close excel writer\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "431f20539060e4195af057caf518edb196c7ace9bef336047b9965dbe49805af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
