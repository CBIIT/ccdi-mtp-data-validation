{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Migrated API Data Downloads\n",
    "2023-07-12 ZD  \n",
    "\n",
    "Verify that the data available as MTP user downloads from the Gene Expression widget are correct. The old downloads pulled a summary file from CHoP's API. After migrating the API server to CBIIT space, we have also changed the data downloads to return the full dataset, rather than summary data, which will allow users to rebuild the plots themselves.  \n",
    "\n",
    "Because the structure of data is very different between the old and new types of downloads, comparisons require transformations. This notebook will compare a sample of old data downloads to new downloads using those transforms. \n",
    "\n",
    "Jira ticket: https://tracker.nci.nih.gov/browse/CCDIMTP-782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "This notebook is intended to be used to compare new MTP Gene Expression data download files in a directory against old files in a different directory.\n",
    "```\n",
    "Example structure:  \n",
    ".\n",
    "└── fileSet/\n",
    "    ├── newData/\n",
    "    │   ├── Filename1\n",
    "    │   ├── Filename2\n",
    "    │   └── Filename3\n",
    "    └── oldData/\n",
    "        ├── Filename1\n",
    "        ├── Filename2\n",
    "        └── Filename3\n",
    "```\n",
    "\n",
    "The notebook will compare the new version of each file in a fileset to the matching old file to check for differences (i.e. `newData/Filename1` vs `oldData/Filename1`). Some transformation steps are run on the newData to mimic the summary statistic steps used by CHoP to deliver the oldData. The comparison is scalable and can compare many files at a time as long as each file in newData has a companion oldData file with identical name for comparison. \n",
    "\n",
    "Specifically, data derived from the following fields are compared within the files:\n",
    "- **x Axis Labels** - Plot labels that determine data grouping. This is provided in both the new and old files. In old files, there is a single row for each label, but in new files, there are many rows for each label. e.g. `Acute Lymphoblastic Leukemia  (Dataset = TARGET, Specimen = Pediatric Primary Tumors, N = 538)`  \n",
    "- **Mean TPM** - Average Transcript Per Million read values for each x Axis Label group rounded to 2 decimal places. This is provided as `tpmMean` in old files and is calculated from `TPM` in new files for comparison.  e.g. `15.95`\n",
    "- **Sample Count** - Number of samples included in each x Axis Label group. This is provided as `boxSampleCount` in both new and files, but is verified by counting the number of rows for each x Axis Label. e.g. `538`\n",
    "\n",
    "Note that the Mean TPM comparison allows for a tolerance of 0.01 difference between provided/old and calculated/new Mean TPM values. This is to allow for any floating point differences in rounding between the provided R-derived means and the new means calculated here with Python. Read more: https://docs.python.org/3/tutorial/floatingpoint.html#tut-fp-issues \n",
    "\n",
    "#### File Preparation\n",
    "Download and organization of files into the comparison directories (e.g. `oldData` and `newData`) is done manually. The `fileSet` folder is used for batching and versioning (e.g. `example` or data download date `20230712`). For notebook development and initial validation, TSV files were downloaded from either the Production tier (old files) or QA tier of MTP. Each API endpoint (download button) delivers data with a different structure. One file was downloaded for each Gene Expression endpoint on each selected page for each tier. The default downloaded filename is `OpenPedCanGeneExpression-{ENSG}.tsv` for target page downloads and `OpenPedCanGeneExpression-{ENSG}-{EFO}.tsv` for evidence page downloads. In order to distinguish downloads from different endpoints on the same page, endpoint descriptors were added to each filename after download (e.g. `OpenPedCanGeneExpression-{ENSG}-gene-all-cancer.tsv`).  \n",
    "\n",
    "\n",
    "#### Initial Validation\n",
    "The sample downloads for initial validation were selected using `dv3_priority_tests.csv` as a guide:  \n",
    "\n",
    "**Endpoints:**  \n",
    "- `gene-all-cancer` (Target)\n",
    "- `gene-all-cancer-tcga` (Target)\n",
    "- `gene-disease-gtex` (Evidence)\n",
    "- `gene-disease-tcga` (Evidence)\n",
    "\n",
    "**Targets:**  \n",
    "- ALK -     ENSG00000171094\n",
    "- BRAF -    ENSG00000157764\n",
    "- CD19 -    ENSG00000177455\n",
    "- EGFR -    ENSG00000146648\n",
    "- FLT3 -    ENSG00000122025\n",
    "\n",
    "**Evidence Combinations**\n",
    "- ALK in neuroblastoma -                    ENSG00000171094-EFO_0000621\n",
    "- FLT3 in acute myeloid leukemia -          ENSG00000122025-EFO_0000222\n",
    "- TP53 in osteosarcoma -                    ENSG00000141510-EFO_0000637\n",
    "- ABL1 in acute lymphoblastic leukemia -    ENSG00000097007-EFO_0000220\n",
    "- PAX3 in osteosarcoma -                    ENSG00000135903-EFO_0000637"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build workflow for handling data download sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_new_df(df):\n",
    "    \"\"\"Transform new data into grouped DataFrame with summary statistics.\"\"\"\n",
    "    \n",
    "    # Build initial summary df with xLabel columns and TPM Mean\n",
    "    df_summarized = df.groupby('xLabel')['tpm'].mean().round(2).reset_index()\n",
    "    df_summarized = df_summarized.rename(columns={'tpm':'tpmMean'})\n",
    "\n",
    "    # Add column for sample/row counts\n",
    "    df_summarized['boxSampleCount'] = df.groupby('xLabel').size().tolist()\n",
    "\n",
    "    return df_summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_data(df_summarized, df_old):\n",
    "    \"\"\"Compare transformed new data against old data. If the data matches, \n",
    "    then a boolean True will be returned. If not, then a dictionary with\n",
    "    additional details will be returned along with the False value.\n",
    "    \n",
    "    :param df_summarized: pandas DataFrame result of summary step\n",
    "    :param df_old: pandas DataFrame \n",
    "    \"\"\"\n",
    "\n",
    "    # Get only comparison columns from old data\n",
    "    df_old = df_old[['xLabel', 'tpmMean', 'boxSampleCount']]\n",
    "\n",
    "    # Sort data by x-axis label for comparison\n",
    "    df_old = df_old.sort_values(by='xLabel', ascending=True).reset_index(drop=True)\n",
    "    df_summarized = df_summarized.sort_values(by='xLabel', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # Check for exact match\n",
    "    comparison_result = df_summarized.equals(df_old)\n",
    "\n",
    "    # Check for columns with mismatched values\n",
    "    if not comparison_result:\n",
    "        # Check x-Axis Labels\n",
    "        match_xLabel = all(df_old['xLabel'] == df_summarized['xLabel'])\n",
    "        # Use relative check of TPM mean with tolerance of 0.01 difference\n",
    "        match_TPMMean = all(np.isclose(a=df_old['tpmMean'], b=df_summarized['tpmMean'], rtol=0.01))\n",
    "        # Check sample counts\n",
    "        match_boxSampleCount = all(df_old['boxSampleCount'] == df_summarized['boxSampleCount'])\n",
    "\n",
    "        # If values still mismatched after tpmMean tolerance, list issues\n",
    "        comparison_result = all([match_xLabel, match_TPMMean, match_boxSampleCount])\n",
    "        if not comparison_result:\n",
    "            return {\n",
    "                'comparison_result': comparison_result,\n",
    "                'match_xLabel': match_xLabel,\n",
    "                'match_tpmMean': match_TPMMean,\n",
    "                'match_boxSampleCount': match_boxSampleCount\n",
    "                }\n",
    "\n",
    "    return comparison_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_data_download_files(newDataPath, oldDataPath):\n",
    "    \"\"\"Main function. Transform new data and compare.\n",
    "\n",
    "    :param newDataPath: directory path of raw new files\n",
    "    :param oldDataPath: directory path of old files\n",
    "    \"\"\"\n",
    "    new_files = os.listdir(newDataPath)\n",
    "    old_files = os.listdir(oldDataPath)\n",
    "\n",
    "    # Sort the files to ensure consistent order for comparison\n",
    "    new_files.sort()\n",
    "    old_files.sort()\n",
    "\n",
    "    # Ensure that directories have identical file counts\n",
    "    if len(new_files) != len(old_files):\n",
    "        raise ValueError(f\"Number of files ({len(new_files)},{len(old_files)}) in comparison directories do not match.\")\n",
    "\n",
    "    compared_data = []\n",
    "\n",
    "    # Iterate through directories to get matching new and old files\n",
    "    for new_file, old_file in zip(new_files, old_files):\n",
    "        new_file_path = os.path.join(newDataPath, new_file)\n",
    "        old_file_path = os.path.join(oldDataPath, old_file)\n",
    "\n",
    "        # Ensure that each file path points to a file\n",
    "        if os.path.isfile(new_file_path) and os.path.isfile(old_file_path):\n",
    "            # Ensure that new_file and old_file have the same filename\n",
    "            if new_file != old_file:\n",
    "                raise ValueError(f\"The filenames {new_file} and {old_file} do not match.\")\n",
    "\n",
    "            # Read the TSV files into DataFrames\n",
    "            df_new = pd.read_csv(new_file_path, delimiter='\\t')\n",
    "            df_old = pd.read_csv(old_file_path, delimiter='\\t')\n",
    "\n",
    "            # Summarize the new data to match format of old data\n",
    "            df_summarized = summarize_new_df(df_new)\n",
    "\n",
    "            # Compare the transformed DataFrame with the old DataFrame\n",
    "            comparison_result = compare_data(df_summarized, df_old)\n",
    "\n",
    "            # Add filename to any mismatched file results\n",
    "            if type(comparison_result)!=bool:\n",
    "                comparison_result.update({\"file:\": new_file})\n",
    "\n",
    "            # Append the comparison result to the list\n",
    "            compared_data.append(comparison_result)\n",
    "\n",
    "    return compared_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run workflow to get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! New data downloads match old data downloads.\n"
     ]
    }
   ],
   "source": [
    "# Define paths for new and old data directories\n",
    "newDataPath = 'data/test/geneExpressionDataDownloads/example/newData/'\n",
    "oldDataPath = 'data/test/geneExpressionDataDownloads/example/oldData/'\n",
    "\n",
    "# Compare data!\n",
    "results = compare_data_download_files(newDataPath, oldDataPath)\n",
    "\n",
    "# If results are good, say so. If not, list issues\n",
    "if all(results):\n",
    "    print(f\"Success! New data downloads match old data downloads.\")\n",
    "else:\n",
    "    print(f\"Error: Some new data downloads DO NOT match old data downloads.\")\n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! New data downloads match old data downloads.\n"
     ]
    }
   ],
   "source": [
    "# Define file set directory\n",
    "fileSet = 'example'\n",
    "\n",
    "# Define paths for new and old data directories\n",
    "newDataPath = 'data/test/geneExpressionDataDownloads/'+fileSet+'/newData/'\n",
    "oldDataPath = 'data/test/geneExpressionDataDownloads/'+fileSet+'/oldData/'\n",
    "\n",
    "# Compare data!\n",
    "results = compare_data_download_files(newDataPath, oldDataPath)\n",
    "\n",
    "# If any results are dict details (data mismatch), show details\n",
    "if any(isinstance(result, dict) for result in results):\n",
    "    print(f\"Error: Some new data downloads do not match old data downloads.\")\n",
    "    for result in results:\n",
    "        if isinstance(result, dict): \n",
    "            print(result)\n",
    "else:\n",
    "    print(f\"Success! New data downloads match old data downloads.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
