{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "093752a4-246c-4d01-9e7d-23520dc6aacb",
   "metadata": {},
   "source": [
    "# Verify the data completeness in Opensearch and clickhouse\n",
    "\n",
    "\n",
    "This data validation step is to make sure the data loaded into our database does not miss any data due to any interuption(internet).  \n",
    "\n",
    "\n",
    "\n",
    "### General idea for verifying data completeness on Opensearch\n",
    "\n",
    "\n",
    "Each line of record in a json file is a document in the opensearch. Based on that consumption, we can count the number of records in index's data files (json files), match it with document stored in the opensearch.\n",
    "\n",
    "\n",
    "\n",
    "###  General idea for verifying data completeness on Clickhouse**\n",
    "\n",
    "There are three tables that imports data from OT's data files. \n",
    "\n",
    "\n",
    "**Table: ot.associations_otf_log**\n",
    "\n",
    "source:/output/etl/json/AOTFClickhouse/ \n",
    "\n",
    "\n",
    "**Table:ot.ml_w2v_log**\n",
    "\n",
    "source: /output/literature/vectors/ \n",
    "\n",
    "\n",
    "**Table: ot.literature_log**\n",
    "\n",
    "source: /output/literature/literatureIndex/ \n",
    "\n",
    "Same as Opensearch, we can count the number of records in the files to learn how many data should in the the clickhouse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2d8def-a3f1-4cf2-99fd-52eb967e72e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec9bc1-ca2f-4f55-8855-b0b63a714d5f",
   "metadata": {},
   "source": [
    "``` console\n",
    "addr = `pwd`\n",
    "b=(`ls `)\n",
    "\n",
    "for a in ${b[*]}; do\n",
    "    echo $a >> ls3.txt\n",
    "    find $addr$a  -name *.json |xargs   wc -l  | awk '{sum+=$1}END{print sum}' >> ls3.txt\n",
    "done\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07036dc-4581-4f25-94df-20010e808d27",
   "metadata": {},
   "source": [
    "## ES(opensearch data validation) \n",
    "\n",
    "You can run the bash scripts in open_search_validation folder. \n",
    "\n",
    "You can simply run the ./load_all script to validate all the datas. \n",
    "\n",
    "\n",
    "```console\n",
    "NCI-02218333-ML:mtp-data-validation cheny39$  ./load_all\n",
    "\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e82c0-ad84-47fb-a617-4017ff529277",
   "metadata": {},
   "source": [
    "### Explaination of code for ES data validation \n",
    "\n",
    "**get number of lines in a index folder** \n",
    "```\n",
    "number_of_doc=$(find $INPUT  -name *.json |xargs   wc -l  | awk '{sum+=$1}END{print sum}' )\n",
    "echo $number_of_doc\n",
    "\n",
    "```\n",
    "\n",
    "**get number of doc from es endpoint** \n",
    "```\n",
    "echo $ES/$INDEX_NAME\"/_count\" \n",
    "\n",
    "curl_es=$(curl  --silent $ES/$INDEX_NAME\"/_count\")\n",
    "\n",
    "echo $curl_es \n",
    "\n",
    "IFS=', ' read -r -a array <<< $curl_es\n",
    "\n",
    "number_of_doc_es=$(echo \"${array:9}\")  \n",
    "\n",
    "```\n",
    "\n",
    "**Compare the numbers** \n",
    "```\n",
    "if [ \"$number_of_doc\" -eq \"$number_of_doc_es\" ]\n",
    "  then\n",
    "  echo \"[GREEN]   $INDEX is GOOD.\"\n",
    "else\n",
    "  echo \"[ERROR]   $INDEX's number does not match.\"\n",
    "fi     # $String is null.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ebe7bc-28d4-498c-a731-25a8992fe7f3",
   "metadata": {},
   "source": [
    "## Find the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54785565-8479-4013-ba13-ce9672bffc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import hashlib\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211c28ae-84dd-4691-89b4-9546b23bdde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Files path\n",
    "AOTFElasticsearch_FIle_PATH = '/Users/cheny39/Documents/work/22.04/output/AOTFElasticsearch/'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e9e89f-e203-49a2-835b-0af418fae261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_files_to_df(path:str, filetype:str='*.json'):\n",
    "    \"\"\"\n",
    "    Load multiple identically-structured jsonl files within a local folder \n",
    "    into a single dataframe. Useful for OpenTargets FTP downloads.\n",
    "\n",
    "    :param path: Relative filepath to the folder containing the jsonl files.\n",
    "    :param filetype: Filetype suffix of files to include. default '*.json'\n",
    "    \"\"\"\n",
    "    \n",
    "    # OT uses 'json' extension for 'jsonl' files\n",
    "    fullPath = path + filetype\n",
    "\n",
    "    # Create list of all files within path folder\n",
    "    files = glob.glob(fullPath)\n",
    "    \n",
    "    print(fullPath)\n",
    "\n",
    "    #Build df by combining all files in path folder\n",
    "    df = pd.concat(\n",
    "            (pd.read_json(f, orient='records', lines=True)\n",
    "            for f in files))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a89d8f-11d2-46c6-b410-9d355c2c1c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cheny39/Documents/work/22.04/output/AOTFElasticsearch/*.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AOTFElasticsearch_DF= load_jsonl_files_to_df(AOTFElasticsearch_FIle_PATH)\n",
    "\n",
    "print(AOTFElasticsearch_DF.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a599af-8b3b-458a-84ce-116392807958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
